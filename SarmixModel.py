# -*- coding: utf-8 -*-
"""Sarmix Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10xWU1SG-YDPVpLxGCMnl4K-S15sI1a-V
"""



#Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
import warnings
warnings.filterwarnings("ignore")
# Function to calculate RMSE
def rmse(actual, predicted):
    return np.sqrt(mean_squared_error(actual, predicted))
data = pd.read_csv("Online Retail.csv")
# Remove negative values from the dataset and combined quantity & price into sales
data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])
data['Sales'] = data['Quantity'] * data['UnitPrice']
data.set_index('InvoiceDate', inplace=True)  # Set 'InvoiceDate' as the index
sales_data = data.groupby(data.index.date)['Sales'].sum().reset_index()
sales_data.columns = ['ds', 'y']
sales_data['ds'] = pd.to_datetime(sales_data['ds'])
sales_data = sales_data[sales_data['y'] > 0]


# Split data into train and test sets
train_size = int(len(sales_data) * 0.8)
train, test = sales_data[:train_size], sales_data[train_size:]


# SARIMA model
#ARIMA Model stated that data was no stationary and differncing was needed so d=1
sarima_model = SARIMAX(train['y'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))

sarima_result = sarima_model.fit()

# Forecast for the next 60 steps
forecast_steps = 60
forecast_sarima = sarima_result.get_forecast(steps=forecast_steps)


# Align forecast index with test data
forecast_sarima_index = test['ds'][:forecast_steps]
forecast_sarima_df = pd.DataFrame({
    'Sarima_Forecast': forecast_sarima.predicted_mean.values
}, index=forecast_sarima_index)



# Combine actual and forecasted values into comparison Data frame
comparison_df = pd.DataFrame({
    'Actual': test['y'][:forecast_steps].values,
    'Sarima_Forecast': forecast_sarima_df['Sarima_Forecast'].values
}, index=forecast_sarima_index)


# Plot the comparison
plt.figure(figsize=(10, 6))
plt.plot(test['ds'], test['y'], label='Actual', marker='o')
plt.plot(forecast_sarima_index, forecast_sarima_df['Sarima_Forecast'], label='Sarima Forecast', linestyle='--', marker='o')
plt.title('Comparison of Sarima Forecast vs Actual')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

# Calculate RMSE and MAPE
sarima_rmse = rmse(test['y'][:forecast_steps], forecast_sarima_df['Sarima_Forecast'])
sarima_mape = mean_absolute_percentage_error(test['y'][:forecast_steps], forecast_sarima_df['Sarima_Forecast'])

# Display evaluation metrics
print(f"\nSarima Model: RMSE = {sarima_rmse:.4f}, MAPE = {sarima_mape:.4%}")

"""1.	Define the problem
I chose to do my machine learning model on the dataset of an online retail store based in the UK between 1/12/2010 to 9/12/2011, because many of the company's consumers are wholesalers. I decided to predict sales trends from these dates for the next two months, so the company can plan its finances. A predictive model is best for this dataset because planning ahead of time how much sales are expected can help the company make decisions on expanding or cutting costs based on predicted sales. If we can properly plan with supplies ready, we can sell more and provide discounts, thereby providing customer satisfaction by providing lower wait times for products. This dataset had a lot of returns that needed to be removed, and had a lot of returns of smaller quantities classified as 0, so they were also removed to strictly focus on the revenue. For this predictive model, I will choose SARIMA as it handles trends and gives interpretable data through predicted values of revenue each day, and plot it visually to present to stakeholders.
2. Data had no missing values, and scaling the data threw off my RMSE and MAPE scores, so it was not used in the model. A quick scan of the data using the head function, I was able to see that my data had negative values in both quantity and price. Price was labeled 0, but then had a transaction of 200 items, which would throw off models’ predictions, if quantity sold could be associated with a price of 0. There was a large chunk of this, so making sure the model only saw and predicted based on relevant data was necessary in cleaning the data. There seemed to be a relationship between price and quantity, so combining them to create sales/revenue was necessary to capture the patterns. There was no title for items sold, so I could not break items down into products to further analyze which was sold more frequently.
3. Model Selection and Implementation:
I decided to do a prediction model for my project, as I believe there are underlying patterns within the dataset. I originally chose the Prophet model to add holidays to data, but since I wasn’t guaranteed that the dataset would follow any significant trend with this, it performed badly with a +200% on RMSE. I chose ARIMA following this, but ARIMA follows a linear path from data with the fewest differences between all of the actual values and the predicted values. Finally, I used SARIMA as it was able to handle cyclinity and maintain ARIMA to account for moving averages in the dataset.
4. Model Evaluation:
The model has an RSME of 16674.2461, which represents squared errors of the means from predicted and actual values. Since we are measuring financial data, I consider this value appropriate, as outliers could have been removed to capture the data patterns better, but there were 3 instances of outliers, which seem to have a pattern of their own. The Mean as a percentage of errors was 33.495%, which is not the most ideal; removing outliers would have greatly improved this percentage. As the model would have a far lower prediction compared to the outlier, this contributed to the larger deviation from actual values.
5. Explainability and Ethics:
Tools such as SHAP and LIME were not used for interpretability, as the results/outputs were interpretable on their own. The SARIMA model has the added benefit of being easily interpretable, without the need to break down results further to explain insights, as it finds patterns based on past trends to make a predicted value. Potential biases in the data include outliers, which skew the model’s performance to provide a more robust prediction. As there could be other factors contributing to sales, it is not taken into consideration with the SARIMA model, as it would add noise to the model. Since this dataset specifically had few features associated with it that could add noise to the model, I chose this specific approach in ML.
6. Reporting and Communication
My SARIMA model had an RSME of 16674.2461 and a MAPE of 33.495%. The visual plot of actual values compared to the SARIMA predicted values was similar and not far apart from each other in terms of revenue. The SARIMA model handled trends, capturing underlying patterns and seasonality hidden in the dataset. There were outliers within the dataset that contributed largely to the large RSME value. For future models, removing outlier data would help create a more robust SARIMA model. Through this model, we can see large shifts in sales throughout the 60 days we tested it on. We can see a pattern of large shifts in sales, with extremely high and extremely low sales. I removed negative values from the dataset, as returns added unnecessary noise to the model; a separate model would need to be created to strictly analyze the return patterns from consumers to understand the underlying problems causing these returns, and incorporating it in the SARIMA model was not ideal.

"""
